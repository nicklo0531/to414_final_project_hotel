---
title: "Writeup"
output:
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 3
    highlight: tango
    theme: lumen
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

<style>
#watermark-logo {
  position: fixed;
  bottom: 25px;
  left: 25px;
  width: 100px;
  opacity: 1;
  z-index: 9999;
}
</style>

<img id="watermark-logo" src="images/logo.png">

![](images/crowne.jpeg)

[Hotel Booking Reservation Dataset](https://www.kaggle.com/datasets/kundanbedmutha/hotel-booking-reservation)

# Step 0 - Why?

We have been hired by IHG, a global Hotel and Resorts brand, to help the management of the City Hotel Ahmedabad. IHG has been facing the problem of revenue loss due to room cancellations. It is shown that around 40% of rooms are canceled after booking. Because cancellations are common, hotels usually “overbook” a little bit to avoid having empty rooms. IHG does not wish to overbook too aggressively since they would have to compensate the guests with a better room and compliments. On the other hand, if we play it too safe and don’t overbook at all, we leave expensive rooms empty. This prompts IHG to explore models that would allow them to overbook the rooms to minimize missed revenue. We aim to predict which reservations are likely to cancel before the guest shows up. 

We act as consultants, and management has provided us with a data set of 4,850 reservations with 27 variables plus the final binary outcome is_canceled, which is 1 if the guest cancelled and 0 if they actually stayed. We are trying to predict this outcome through the other variables that describe what the hotel already knows at booking time like lead time, length of previous stay, number of guests, room type, booking channel, and previous cancellations.
	
In this project our prediction task is to estimate, for each new booking, the probability that it will be canceled. We will build and compare several models including Logistic Regression, KNN (k-Nearest-Neighbours), ANN (Artificial Neural Network), Decision Tree, Random Forest, and Support Vector Machine. We aim to optimize precision since we would want to avoid false positives (predicting the guest to cancel but they actually show up) which would incur extra cost. We'll then build a stacked meta model (second layer decision tree) that leverages the predicted probabilities from the base models as inputs and produces a final cancellation probability which the hotel can use when setting its overbooking policy.

We will evaluate the differences between our baseline without a model, all individual models, a very conservative logistic regression model that prioritizes minimizing false positives, and the stacked model in classic statistical metrics and compute the expected net financial impact of model implementation. From this analysis, we are able to provide the management with a recommendation of which model to implement and how to do so. They will also be able to optimize room reservations to prevent revenue loss due to empty rooms and overbooking.

# Step 1&2&3: Load, Clean, and Split Data

Refer to the *data_cleaning_splitting.Rmd* under the data folder.

```{r data}
source("data/data_cleaning_splitting.R")
```

# Step 4&5: Create, Predict Models

## First-level Models

### A - Logistic Regression

```{r logistic_regression_results}
source("models/LogisticRegression.R")
```

### B - KNN

```{r knn_results}
source("models/KNN.R")
```

In order to optimize the KNN model, we tuned k by testing different values from 0 to 31. After obtaining the accuracy, sensitivity and specificity for each K, we have selected the one with the highest specificity. This is because false positives, predicting a cancellation when the guests actually show up, are very expensive. We want a model that can correctly identify non-cancellations.

### C - ANN

```{r ann_results}
source("models/ANN.R")
```

Due to expensive computations using ANN, we took a subset of the train data since the full dataset takes more than 20 minutes to run. We played around with different neurons in two layers and ultimately applied 3 neurons for the first layer and 2 neurons for the second layer.

### D - SVM

```{r svm_results}
source("models/SVM.R")
```

We put three SVM kernels- linear, radial, and sigmoid- into trials to look for the optimal kernel. The linear kernel slightly outperformed radial, so we applied it for the final model.

### E - Decision Tree

```{r dt_results}
source("models/DecisionTree.R")
```


### F - Random Forest

```{r rf_results}
source("models/RandomForest.R")
```

To model cancellation behaviour, we trained a Random Forest classifier. We tuned the number of trees (ntree) by testing values from 100 to 2000 in steps of 100, using out-of-sample precision as the primary metric. Performance plateaued quickly, and 300 trees delivered the best balance of accuracy, sensitivity, and precision, so we selected ntree = 300 for the final model.

## Stacked Models

### Second-layer Decision Tree

```{r stacked_dt}
source("models/metaDT.R")
```

### Second-layer Logistic Regression

```{r stacked_lr}
source("models/StackedLR.R")
```


Given that giving someone a room at a different hotel plus compensation is about twice as expensive as an empty $500 room, the Random Forest with threshold 0.55 is the cheapest policy: it creates the lowest average loss per reservation. The other models either send too many guests away to other hotels or leave too many rooms empty, so their average cost per booking is higher.

Looking at the table itself, each row is the “best” version of that model once we plug in our cost numbers. The Threshold column shows how high the predicted cancel-probability has to be before we treat a booking as a cancellation risk. Models with very high thresholds like the ANN at 0.99 are extremely picky and only flag the riskiest guests, which gives them huge Precision but lower Sensitivity because they miss a lot of actual cancellations. On the other side, the logistic model at 0.01 basically flags almost everyone, so its sensitivity is higher but its precision drops. Accuracy and Kappa summarize overall performance, but the main number we care about is AvgCost, which turns all those trade-offs into an estimated dollar loss per reservation. Random Forest ends up with the lowest AvgCost, while the stacked model and SVM are close behind, and the ANN is the most expensive because it leaves too many empty rooms.

with cost matrix (?)

without cost matrix (??)


# Step 7: Implement Model


Limitations: Did not explore financial impact by having a policy that 

Dynamic
